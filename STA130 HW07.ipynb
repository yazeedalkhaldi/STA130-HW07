{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472b6295",
   "metadata": {},
   "source": [
    "# 1. Explain succinctly in your own words (but working with a ChatBot if needed)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161a87b",
   "metadata": {},
   "source": [
    "## 1.the difference between Simple Linear Regression and Multiple Linear Regression; and the benefit the latter provides over the former"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e2a58",
   "metadata": {},
   "source": [
    "Multiple Linear Regression is just a model of linear equation with the relationship of more than one x and y values represented by the equation:y = β0 + β1*x1 + β2*x2 + ⋯ + βn*xn\n",
    "\n",
    "Simple Linear Regression is just a model of linear equation with the relationship of one x and one y value represented by the equation: y = β0 + β1*x\n",
    "\n",
    "The benefit the latter provides over the former is that it captures more complex relationships by considering additional factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc794b0",
   "metadata": {},
   "source": [
    "## 2.the difference between using a continuous variable and an indicator variable in Simple Linear Regression; and these two linear forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ad23f",
   "metadata": {},
   "source": [
    "A continuous variable can take any value to represent the fluctuations of the graph in response to the variables taken into account.\n",
    "\n",
    "An indicator variable only \"represents categories\" which change the regression line, either shifting up or down, and doesnt affect the slope.\n",
    "\n",
    "Linear form with a continuous variable has the equation; y = β0 + β1*x \n",
    "\n",
    "Linear from with an indicator variable is similar to the one above but changes depending on the shift in regression line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf0a71",
   "metadata": {},
   "source": [
    "## 3.the change that happens in the behavior of the model (i.e., the expected nature of the data it models) when a single indicator variable is introduced alongside a continuous variable to create a Multiple Linear Regression; and these two linear forms (i.e., the Simple Linear Regression versus the Multiple Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e3b2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.228109\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>str8fyre</td>     <th>  No. Observations:  </th>  <td>   800</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   788</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 14 Nov 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.05156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>22:34:30</td>     <th>  Log-Likelihood:    </th> <td> -182.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -192.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.04757</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                      <td></td>                        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                <td>   -3.2644</td> <td>    0.714</td> <td>   -4.572</td> <td> 0.000</td> <td>   -4.664</td> <td>   -1.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                        <td>    4.3478</td> <td>    2.179</td> <td>    1.996</td> <td> 0.046</td> <td>    0.078</td> <td>    8.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 2\") == \"None\")[T.True]</th>         <td>    1.5432</td> <td>    0.853</td> <td>    1.810</td> <td> 0.070</td> <td>   -0.128</td> <td>    3.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>                       <td>   -0.0574</td> <td>    0.468</td> <td>   -0.123</td> <td> 0.902</td> <td>   -0.975</td> <td>    0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>                       <td>   -0.6480</td> <td>    0.466</td> <td>   -1.390</td> <td> 0.164</td> <td>   -1.561</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>                       <td>   -0.8255</td> <td>    0.545</td> <td>   -1.516</td> <td> 0.130</td> <td>   -1.893</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>                       <td>   -0.5375</td> <td>    0.449</td> <td>   -1.198</td> <td> 0.231</td> <td>   -1.417</td> <td>    0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>                       <td>    0.3213</td> <td>    0.477</td> <td>    0.673</td> <td> 0.501</td> <td>   -0.614</td> <td>    1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                   <td>    0.0172</td> <td>    0.006</td> <td>    3.086</td> <td> 0.002</td> <td>    0.006</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                 <td>   -0.0365</td> <td>    0.019</td> <td>   -1.884</td> <td> 0.060</td> <td>   -0.074</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                  <td>   -0.0098</td> <td>    0.008</td> <td>   -1.247</td> <td> 0.213</td> <td>   -0.025</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:I(Q(\"Type 2\") == \"None\")[T.True]</th> <td>   -0.0197</td> <td>    0.012</td> <td>   -1.651</td> <td> 0.099</td> <td>   -0.043</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                           &     str8fyre     & \\textbf{  No. Observations:  } &      800    \\\\\n",
       "\\textbf{Model:}                                   &      Logit       & \\textbf{  Df Residuals:      } &      788    \\\\\n",
       "\\textbf{Method:}                                  &       MLE        & \\textbf{  Df Model:          } &       11    \\\\\n",
       "\\textbf{Date:}                                    & Thu, 14 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &  0.05156    \\\\\n",
       "\\textbf{Time:}                                    &     22:34:30     & \\textbf{  Log-Likelihood:    } &   -182.49   \\\\\n",
       "\\textbf{converged:}                               &       True       & \\textbf{  LL-Null:           } &   -192.41   \\\\\n",
       "\\textbf{Covariance Type:}                         &    nonrobust     & \\textbf{  LLR p-value:       } &  0.04757    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                  & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                &      -3.2644  &        0.714     &    -4.572  &         0.000        &       -4.664    &       -1.865     \\\\\n",
       "\\textbf{Legendary[T.True]}                        &       4.3478  &        2.179     &     1.996  &         0.046        &        0.078    &        8.618     \\\\\n",
       "\\textbf{I(Q(\"Type 2\") == \"None\")[T.True]}         &       1.5432  &        0.853     &     1.810  &         0.070        &       -0.128    &        3.215     \\\\\n",
       "\\textbf{C(Generation)[T.2]}                       &      -0.0574  &        0.468     &    -0.123  &         0.902        &       -0.975    &        0.861     \\\\\n",
       "\\textbf{C(Generation)[T.3]}                       &      -0.6480  &        0.466     &    -1.390  &         0.164        &       -1.561    &        0.265     \\\\\n",
       "\\textbf{C(Generation)[T.4]}                       &      -0.8255  &        0.545     &    -1.516  &         0.130        &       -1.893    &        0.242     \\\\\n",
       "\\textbf{C(Generation)[T.5]}                       &      -0.5375  &        0.449     &    -1.198  &         0.231        &       -1.417    &        0.342     \\\\\n",
       "\\textbf{C(Generation)[T.6]}                       &       0.3213  &        0.477     &     0.673  &         0.501        &       -0.614    &        1.257     \\\\\n",
       "\\textbf{Attack}                                   &       0.0172  &        0.006     &     3.086  &         0.002        &        0.006    &        0.028     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                 &      -0.0365  &        0.019     &    -1.884  &         0.060        &       -0.074    &        0.001     \\\\\n",
       "\\textbf{Defense}                                  &      -0.0098  &        0.008     &    -1.247  &         0.213        &       -0.025    &        0.006     \\\\\n",
       "\\textbf{Defense:I(Q(\"Type 2\") == \"None\")[T.True]} &      -0.0197  &        0.012     &    -1.651  &         0.099        &       -0.043    &        0.004     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               str8fyre   No. Observations:                  800\n",
       "Model:                          Logit   Df Residuals:                      788\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Thu, 14 Nov 2024   Pseudo R-squ.:                 0.05156\n",
       "Time:                        22:34:30   Log-Likelihood:                -182.49\n",
       "converged:                       True   LL-Null:                       -192.41\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.04757\n",
       "============================================================================================================\n",
       "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                   -3.2644      0.714     -4.572      0.000      -4.664      -1.865\n",
       "Legendary[T.True]                            4.3478      2.179      1.996      0.046       0.078       8.618\n",
       "I(Q(\"Type 2\") == \"None\")[T.True]             1.5432      0.853      1.810      0.070      -0.128       3.215\n",
       "C(Generation)[T.2]                          -0.0574      0.468     -0.123      0.902      -0.975       0.861\n",
       "C(Generation)[T.3]                          -0.6480      0.466     -1.390      0.164      -1.561       0.265\n",
       "C(Generation)[T.4]                          -0.8255      0.545     -1.516      0.130      -1.893       0.242\n",
       "C(Generation)[T.5]                          -0.5375      0.449     -1.198      0.231      -1.417       0.342\n",
       "C(Generation)[T.6]                           0.3213      0.477      0.673      0.501      -0.614       1.257\n",
       "Attack                                       0.0172      0.006      3.086      0.002       0.006       0.028\n",
       "Attack:Legendary[T.True]                    -0.0365      0.019     -1.884      0.060      -0.074       0.001\n",
       "Defense                                     -0.0098      0.008     -1.247      0.213      -0.025       0.006\n",
       "Defense:I(Q(\"Type 2\") == \"None\")[T.True]    -0.0197      0.012     -1.651      0.099      -0.043       0.004\n",
       "============================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example of how you can do this\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "pokeaman = pd.read_csv(url).fillna('None')\n",
    "\n",
    "pokeaman['str8fyre'] = (pokeaman['Type 1']=='Fire').astype(int)\n",
    "linear_model_specification_formula = \\\n",
    "'str8fyre ~ Attack*Legendary + Defense*I(Q(\"Type 2\")==\"None\") + C(Generation)'\n",
    "log_reg_fit = smf.logit(linear_model_specification_formula, data=pokeaman).fit()\n",
    "log_reg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad74658",
   "metadata": {},
   "source": [
    "Adding indicator variable changes the intercept while still maintaining the slope that was given by the continuous variable.\n",
    "\n",
    "Simple Linear Regression with one continuous variable is 𝑦 = 𝛽0 + 𝛽1*𝑥. With an additional indicator in Multiple Linear Regression, the form becomes 𝑦 = 𝛽0 + 𝛽1*𝑥 + 𝛽2*𝑧, where z is the indicator variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46b494",
   "metadata": {},
   "source": [
    "## 4.the effect of adding an interaction between a continuous and an indicator variable in Multiple Linear Regression models; and this linear form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4200dc6",
   "metadata": {},
   "source": [
    "It lets the the model estimate a different slope for the continuous variable in each category\n",
    "Represented by the equation; 𝑦 = 𝛽0 + 𝛽1*𝑥 + 𝛽2*𝑧 + 𝛽3*(x * z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c79dff1",
   "metadata": {},
   "source": [
    "## 5.the behavior of a Multiple Linear Regression model (i.e., the expected nature of the data it models) based only on indicator variables derived from a non-binary categorical variable; this linear form; and the necessarily resulting binary variable encodings it utilizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b98caf",
   "metadata": {},
   "source": [
    "It captures the effect of each category by using binary dummy variables\n",
    "Represented by the equation; y = β0 + β1D1 + β2D2 + ⋯ + βk−1*Dk−1, where Di are the dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a37d94c",
   "metadata": {},
   "source": [
    "# 2. Explain in your own words (but working with a ChatBot if needed) what the specific (outcome and predictor) variables are for the scenario below; whether or not any meaningful interactions might need to be taken into account when predicting the outcome; and provide the linear forms with and without the potential interactions that might need to be considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e862db0a",
   "metadata": {},
   "source": [
    "## 1.Explain how to use these two formulas to make predictions of the outcome, and give a high level explaination in general terms of the difference between predictions from the models with and without the interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb3dbc1",
   "metadata": {},
   "source": [
    "Without Interactions: Sales = β0 + β1(TV Budget) + β2(Online Budget)\n",
    "In this form, each advertising budget contributes independently to sales. The effect of the TV budget is constant, regardless of the online budget, and vice versa.\n",
    "\n",
    "With Interactions: Sales = β0 + β1(TV Budget) + β2(Online Budget) + β3(TV Budget×Online Budget) \n",
    "Here, the interaction term(TV Budget×Online Budget)(TV Budget×Online Budget) allows for the combined effect of both budgets, meaning the impact of one advertising type on sales can vary depending on the level of the other.\n",
    "\n",
    "Assuming that every kind of advertising has a separate impact on sales, the additive model offers a simple forecast. However, the potential collaboration between the two budgets is captured by the interactive model, whereby lavish spending on both might result in a greater sales gain than each sort of advertising alone. If both forms of advertising have an impact on one another, this interaction may provide a more accurate forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d069640",
   "metadata": {},
   "source": [
    "## 2.Explain how to update and use the implied two formulas to make predictions of the outcome if, rather than considering two continuous predictor variables, we instead suppose the advertisement budgets are simply categorized as either \"high\" or \"low\" (binary variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40583f",
   "metadata": {},
   "source": [
    "Without Interaction: Sales = 𝛽0 + 𝛽1(TV High) + 𝛽2(Online High)\n",
    "TV High and  Online High are binary variables (1 if high, 0 if low). This model predicts an increase in sales if the TV or online budget is high, without considering a combined effect.\n",
    "\n",
    "With Interaction: Sales = β0 + β1(TV High) + β2(Online High) + β3(TV High×Online High)\n",
    "This model includes an interaction term (TV High×Online High)(TV High×Online High), capturing any added effect on sales when both budgets are high. The interaction term adjusts the prediction to account for combined high spending.\n",
    "\n",
    "The additive model posits that each \"high\" or \"low\" budget level has a separate impact on sales in the binary scenario. The situation where two high budgets might have a combined effect—for example, a more significant rise in sales than either high budget alone would produce—is captured by the interactive model. If the interaction has a big effect on sales, this can give a more accurate forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b282b36e",
   "metadata": {},
   "source": [
    "# 3. Use smf to fit multiple linear regression models to the course project dataset from the canadian social connection survey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf8f99",
   "metadata": {},
   "source": [
    "## 1.for an additive specification for the linear form based on any combination of a couple continuous, binary, and/or categorical variables and a CONTINUOUS OUTCOME varaible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c900c",
   "metadata": {},
   "source": [
    "## 2.for a synertistic interaction specification for the linear form based on any combination of a couple continuous, binary, and/or categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d71a77",
   "metadata": {},
   "source": [
    "## 3.and interpretively explain your linear forms and how to use them to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f9091",
   "metadata": {},
   "source": [
    "## 4.and interpret the statistical evidence associated with the predictor variables for each of your model specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5764390",
   "metadata": {},
   "source": [
    "## 5. and finally use plotly to visualize the data with corresponding \"best fit lines\" for a model with continuous plus binary indicator specification under both (a) additive and (b) synergistic specifications of the linear form (on separate figures), commenting on the apparent necessity (or lack thereof) of the interaction term for the data in question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b513b",
   "metadata": {},
   "source": [
    "- Step 1: Load and Explore the CSCS Data\n",
    "Ensure you have access to the dataset and have defined your continuous outcome and predictor variables (continuous, binary, and categorical). Let’s assume the outcome variable is a continuous measure like \"social connectedness score.\"\n",
    "\n",
    "- Step 2: Define Additive and Interaction Model Specifications\n",
    "1. Additive Model Specification: In an additive model, each predictor variable contributes independently to the outcome.\n",
    "\n",
    "Here:\n",
    "age and income are continuous predictors.\n",
    "region is a categorical predictor.\n",
    "social_activity is a binary indicator (e.g., 1 if socially active, 0 if not).\n",
    "\n",
    "2. Interaction (Synergistic) Model Specification: The interaction model includes terms that allow the effects of predictors to depend on each other.\n",
    "\n",
    "Here, we introduce interaction terms:\n",
    "age * income: Allows the effect of age on social connectedness to vary based on income.\n",
    "C(region) * social_activity: Accounts for potential interaction between region and social activity status.\n",
    "\n",
    "- Step 3: Interpret Statistical Evidence\n",
    "For each model, examine the summary output:\n",
    "\n",
    "Coefficients: Reflect the strength and direction of the relationships.\n",
    "p-values: Show the statistical significance of each predictor (a low p-value indicates strong evidence that the predictor affects the outcome).\n",
    "R-squared: Indicates the proportion of variability in the outcome explained by the model.\n",
    "In the additive model, the coefficients tell us the independent impact of each predictor on the connectedness score. For instance, if income has a positive and statistically significant coefficient, it means higher income is associated with a higher connectedness score, regardless of other factors.\n",
    "In the interaction model, significant interaction terms (e.g., age:income) suggest that the effect of age on connectedness score depends on income. If both C(region) and social_activity have a significant interaction, it indicates that the region modifies the effect of social activity status on connectedness.\n",
    "\n",
    "- Step 4: Visualize Using Plotly\n",
    "Interpretation of Visualization\n",
    "1. Additive Model (Figure A): The trendline fits across all data points regardless of the binary grouping of social activity, suggesting a uniform effect of age on connectedness.\n",
    "2. Interaction Model (Figure B): Separate trendlines for each social activity group allow the slope for age to differ based on social activity status. This can illustrate the necessity of an interaction term if the slopes vary significantly between groups, suggesting that age’s effect on connectedness changes based on social activity.\n",
    "\n",
    "\n",
    "\n",
    "By visualizing both models, you can observe whether the interaction term is essential. If there’s no noticeable difference between trendlines in Figure B, the interaction term might not be necessary. However, if the trendlines diverge, the interaction term is likely justified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f1632",
   "metadata": {},
   "source": [
    "#### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69786779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Example formula with continuous, binary, and categorical predictors\n",
    "model_additive = smf.ols(formula='connectedness_score ~ age + income + C(region) + social_activity', data=cscs_data).fit()\n",
    "model_additive.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b774ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with interaction terms\n",
    "model_interaction = smf.ols(formula='connectedness_score ~ age * income + C(region) * social_activity', data=cscs_data).fit()\n",
    "model_interaction.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98470e09",
   "metadata": {},
   "source": [
    "#### Step 4: Visualize Using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcbda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# Assuming \"age\" is a continuous predictor and \"social_activity\" is binary\n",
    "fig_additive = px.scatter(cscs_data, x='age', y='connectedness_score', color='social_activity',\n",
    "                          trendline=\"ols\", trendline_scope=\"overall\", title=\"Additive Model\")\n",
    "fig_additive.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_interaction = px.scatter(cscs_data, x='age', y='connectedness_score', color='social_activity',\n",
    "                             trendline=\"ols\", trendline_scope=\"group\", trendline_color_override=\"red\",\n",
    "                             title=\"Interaction Model with Age and Social Activity Interaction\")\n",
    "fig_interaction.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5fac87",
   "metadata": {},
   "source": [
    "# 4. Explain the apparent contradiction between the factual statements regarding the fit below that \"the model only explains 17.6% of the variability in the data\" while at the same time \"many of the coefficients are larger than 10 while having strong or very strong evidence against the null hypothesis of 'no effect'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf0a758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e45be52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:59:37</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     20:59:37     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        20:59:37   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e1a6f4",
   "metadata": {},
   "source": [
    "Limited Explanatory Power:\n",
    "\n",
    "- The low R-squared value implies that, despite the significant predictors, the model does not capture much of the variability in HP.\n",
    "- This could be due to the exclusion of other important variables that affect HP, leading to a model that, while statistically valid, lacks comprehensive explanatory power.\n",
    "\n",
    "Significance Reflects Reliability, Not Magnitude of Effect:\n",
    "\n",
    "- Statistical significance indicates that the observed relationships are unlikely to be due to chance, but it does not measure the strength or practical importance of these relationships.\n",
    "- A predictor can have a statistically significant effect with a large coefficient, yet still explain only a small portion of the variance in the dependent variable if other influential factors are missing from the model.\n",
    "\n",
    "The model's low R-squared value alongside significant coefficients underscores the importance of distinguishing between statistical significance and the overall explanatory power of a model. It highlights the need for a comprehensive approach in model building, ensuring that all relevant factors are considered to accurately capture the variability in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40c767",
   "metadata": {},
   "source": [
    "# 5. Discuss the following (five cells of) code and results with a ChatBot and based on the understanding you arrive at in this conversation explain what the following (five cells of) are illustrating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf11d73",
   "metadata": {},
   "source": [
    "#### Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a58cc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>str8fyre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  str8fyre  \n",
       "370       55       65     70           3      False         0  \n",
       "6        109       85    100           1      False         1  \n",
       "242      105       75     45           2      False         0  \n",
       "661       70       85     50           5      False         0  \n",
       "288       20       30     20           3      False         0  \n",
       "..       ...      ...    ...         ...        ...       ...  \n",
       "522      130       95     65           4      False         0  \n",
       "243       65       45     75           2      False         0  \n",
       "797      150      130     70           6       True         0  \n",
       "117       60       45     35           1      False         0  \n",
       "409      120       90    120           3      False         0  \n",
       "\n",
       "[400 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c767e7c",
   "metadata": {},
   "source": [
    "- Purpose: This cell prepares the data for training and testing the models.\n",
    "1. The dataset is split into a training set (pokeaman_train) and a test set (pokeaman_test), with each set holding 50% of the data.\n",
    "2. NaN values in the \"Type 2\" column are replaced with \"None\" to avoid errors in the model caused by missing values.\n",
    "3. np.random.seed(130) ensures reproducibility of the random split.\n",
    "- Illustration: Demonstrates data preprocessing and creating a train-test split, a fundamental step for evaluating model performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d801f8",
   "metadata": {},
   "source": [
    "#### Cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb975884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:35:38</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     22:35:38     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        22:35:38   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d0974d",
   "metadata": {},
   "source": [
    "- Purpose: This cell specifies and fits a simple linear regression model (model3) with HP as the outcome variable and Attack and Defense as predictor variables.\n",
    "- Illustration: Shows how a basic linear model can be created using only two predictors, focusing on a limited set of features to predict the HP variable. The summary output from model3_fit.summary() will provide insights into the coefficients, statistical significance, R-squared value, and overall model performance on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd096c92",
   "metadata": {},
   "source": [
    "#### Cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9ab5673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model3)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece79166",
   "metadata": {},
   "source": [
    "- Purpose: This cell evaluates the performance of model3 on both the training set (in-sample) and the test set (out-of-sample).\n",
    "1. The in-sample R-squared (from model3_fit.rsquared) measures how well the model fits the training data.\n",
    "2. The out-of-sample R-squared (from np.corrcoef(y, yhat_model3)[0,1]**2) assesses the model's predictive performance on the test set.\n",
    "- Illustration: Highlights the difference between in-sample and out-of-sample R-squared values, which can reveal potential overfitting if in-sample performance is significantly better than out-of-sample performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93898b",
   "metadata": {},
   "source": [
    "#### Cell 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad77740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:35:44</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     22:35:44     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        22:35:44   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97d821",
   "metadata": {},
   "source": [
    "- Purpose: This cell specifies and fits a more complex regression model (model4) with multiple interaction terms across several predictors (Attack, Defense, Speed, Legendary, Sp. Def, Sp. Atk).\n",
    "1. This complex formula aims to capture the interactions among these variables, potentially leading to a more nuanced model of HP.\n",
    "2. The comment warns against adding too many high-dimensional interactions, which would create an unmanageably large model.\n",
    "- Illustration: Demonstrates the creation of a high-complexity model with multiple interaction terms. This model aims to capture more complex relationships, but there is also the risk of overfitting due to the high number of interaction terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc63f537",
   "metadata": {},
   "source": [
    "### Cell 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "216297af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e82b9a",
   "metadata": {},
   "source": [
    "- Purpose: This cell evaluates model4 on both the training set (in-sample) and the test set (out-of-sample) in the same way as in Cell 3.\n",
    "- Illustration: By comparing the in-sample and out-of-sample R-squared values for the complex model, this cell illustrates the potential overfitting that can arise when including numerous interaction terms. A large drop in out-of-sample performance compared to in-sample would indicate overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9fe81f",
   "metadata": {},
   "source": [
    "#### Summary of What These Cells Illustrate\n",
    "These cells collectively illustrate a typical workflow for building and evaluating regression models, showing both simple and complex specifications:\n",
    "\n",
    "1. Data Preparation and Splitting: Ensures data is ready for modeling and allows for proper model evaluation using a train-test split.\n",
    "2. Model Specification: Starts with a basic model (Cell 2) and progresses to a complex model with multiple interaction terms (Cell 4).\n",
    "3. Performance Evaluation: Calculates and compares in-sample and out-of-sample R-squared values for both models (Cells 3 and 5) to assess predictive power and the risk of overfitting.\n",
    "\n",
    "By analyzing both a simple and complex model, this example highlights the trade-off between model complexity and generalizability, helping illustrate how adding more features and interactions can increase the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1291a",
   "metadata": {},
   "source": [
    "# 6. Work with a ChatBot to understand how the model4_linear_form (linear form specification of model4) creates new predictor variables as the columns of the so-called \"design matrix\" model4_spec.exog (model4_spec.exog.shape) used to predict the outcome variable model4_spec.endog and why the so-called multicollinearity in this \"design matrix\" (observed in np.corrcoef(model4_spec.exog)) contribues to the lack of \"out of sample\" generalization of predictions from model4_fit; then, explain this consisely in your own works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d5538",
   "metadata": {},
   "source": [
    "1. Model4 Linear Form (model4_linear_form):\n",
    "\n",
    "- The model4_linear_form specification includes interaction terms among multiple predictors: Attack, Defense, Speed, Legendary, Sp. Def, and Sp. Atk.\n",
    "- When fitting a model with this specification, the code generates a design matrix (model4_spec.exog), where each column represents a predictor (or interaction term) in the model.\n",
    "- Interaction terms multiply predictors together (e.g., Attack * Defense * Speed), leading to many new columns in this design matrix.\n",
    "- The result is a high-dimensional matrix with potentially highly correlated (or redundant) columns due to the interactions, leading to multicollinearity.\n",
    "\n",
    "\n",
    "2. Multicollinearity in the Design Matrix:\n",
    "\n",
    "- Multicollinearity occurs when two or more predictors in the design matrix are highly correlated, making it difficult to determine their individual effects on the outcome.\n",
    "- This can be observed by checking correlations in the design matrix (e.g., np.corrcoef(model4_spec.exog)) and by looking at the Condition Number from the model summary, which indicates the degree of multicollinearity.\n",
    "- High multicollinearity (indicated by an extremely high condition number) can lead to unstable coefficients, where small changes in the data cause large fluctuations in coefficient estimates, thus reducing the model's ability to generalize to new data (i.e., poor \"out-of-sample\" performance).\n",
    "\n",
    "\n",
    "3. Condition Number and Model Stability:\n",
    "\n",
    "- The Condition Number is a measure of how sensitive the model is to slight changes in the predictors, with higher values indicating more severe multicollinearity.\n",
    "- Without centering and scaling, model4_fit has a very high Condition Number (e.g., 10^12to 10^15), indicating that the model is extremely sensitive to predictor variations, making the model prone to poor generalization.\n",
    "- This issue is somewhat alleviated in model3_fit by centering and scaling, which reduces the Condition Number to 1.66, suggesting minimal multicollinearity and more stability.\n",
    "\n",
    "\n",
    "#### Impact of Centering and Scaling\n",
    "\n",
    "4. Centering and Scaling (model4_linear_form_CS):\n",
    "\n",
    "- By centering and scaling the continuous predictors (e.g., scale(center(Attack))), each predictor is adjusted to have a mean of zero and a standard deviation of one, which can reduce multicollinearity and make the model more stable.\n",
    "- After centering and scaling, the Condition Number for model3_center_scale_fit becomes low (around 1.66), but model4_CS_fit still has a high Condition Number (around 10^15), indicating that interactions among multiple variables contribute to high multicollinearity that centering and scaling alone cannot resolve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c917c7",
   "metadata": {},
   "source": [
    "# 7. Discuss with a ChatBot the rationale and principles by which model5_linear_form is extended and developed from model3_fit and model4_fit; model6_linear_form is extended and developed from model5_linear_form; and model7_linear_form is extended and developed from model6_linear_form; then, explain this breifly and consisely in your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc988f49",
   "metadata": {},
   "source": [
    "### Model Progression Overview\n",
    "\n",
    "\n",
    "1. model3 to model4: Increasing Complexity with Interactions\n",
    "\n",
    "- model3: A simple linear regression using only Attack and Defense as predictors.\n",
    "- model4: Extends model3 by adding interactions among several predictors (e.g., Attack, Defense, Speed, Legendary, Sp. Def, and Sp. Atk).\n",
    "- Rationale: Adding interactions allows the model to capture potential combined effects of variables, which could improve predictive accuracy. However, the high complexity may lead to multicollinearity and poor out-of-sample performance, as seen in the high Condition Number.\n",
    "\n",
    "\n",
    "2. model5: Adding Relevant Predictors Without Excessive Interactions\n",
    "\n",
    "- Specification: Includes additional main effects (e.g., Speed, Legendary, Sp. Def, Sp. Atk, Generation, and Type 1 and Type 2) but avoids high-order interactions.\n",
    "- Rationale: This approach incorporates a broader range of features without the computational expense and instability associated with complex interaction terms. Adding categorical variables like Generation and Type captures group-level variations, potentially boosting interpretability and predictive performance without over-complicating the model.\n",
    "\n",
    "3. model6: Refining Predictors Based on Statistical Significance\n",
    "\n",
    "- Specification: Focuses on a subset of predictors from model5 that showed significance (e.g., Attack, Speed, Sp. Def, Sp. Atk, and indicators for Type 1 == \"Normal\" or \"Water\" and Generation 2 and 5).\n",
    "- Rationale: Removing nonsignificant predictors simplifies the model, helping to reduce multicollinearity and avoid overfitting. This refinement is based on empirical evidence, retaining only variables that appear to have a significant effect on HP.\n",
    "\n",
    "\n",
    "4. model7: Adding Selected Interactions for Key Predictors\n",
    "\n",
    "- Specification: Includes interactions among the primary continuous predictors (Attack, Speed, Sp. Def, Sp. Atk), along with selected binary indicators for Type and Generation.\n",
    "- Rationale: Adding limited interactions among the most relevant continuous predictors allows the model to account for complex relationships where these variables jointly influence HP. This targeted interaction approach balances model complexity with interpretability.\n",
    "\n",
    "\n",
    "5. model7 with Centering and Scaling (model7_CS)\n",
    "\n",
    "- Specification: Uses centered and scaled versions of continuous predictors to reduce multicollinearity while preserving indicator variables for categorical effects.\n",
    "- Rationale: Centering and scaling reduce the Condition Number from over 2 trillion to a manageable 15.4, which stabilizes coefficient estimates and improves the model’s ability to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e64f2",
   "metadata": {},
   "source": [
    "# 8. Work with a ChatBot to write a for loop to create, collect, and visualize many different paired \"in sample\" and \"out of sample\" model performance metric actualizations (by not using np.random.seed(130) within each loop iteration); and explain in your own words the meaning of your results and purpose of this demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b71db5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Pokémon dataset\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "pokeaman = pd.read_csv(url)\n",
    "pokeaman.fillna('None', inplace=True)  # Replace NaNs in 'Type 2' with 'None'\n",
    "\n",
    "# Initialize lists to collect R-squared values\n",
    "in_sample_r_squared = []\n",
    "out_of_sample_r_squared = []\n",
    "\n",
    "# Number of iterations for repeated train-test splits\n",
    "iterations = 100\n",
    "\n",
    "for _ in range(iterations):\n",
    "    # Split data without setting a random seed\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Specify and fit model (using model7 example linear form)\n",
    "    model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "    model_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "    model_fit = model_spec.fit()\n",
    "    \n",
    "    # Predict and calculate in-sample R-squared\n",
    "    in_sample_r_squared.append(model_fit.rsquared)\n",
    "    \n",
    "    # Predict and calculate out-of-sample R-squared\n",
    "    y_test = pokeaman_test.HP\n",
    "    yhat_out_of_sample = model_fit.predict(pokeaman_test)\n",
    "    out_of_sample_r_squared.append(np.corrcoef(y_test, yhat_out_of_sample)[0,1]**2)\n",
    "\n",
    "# Convert results to DataFrame for plotting\n",
    "results_df = pd.DataFrame({\n",
    "    'In-sample R-squared': in_sample_r_squared,\n",
    "    'Out-of-sample R-squared': out_of_sample_r_squared\n",
    "})\n",
    "\n",
    "# Visualization of in-sample and out-of-sample R-squared distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(results_df['In-sample R-squared'], bins=20, alpha=0.7, label='In-sample R-squared')\n",
    "plt.hist(results_df['Out-of-sample R-squared'], bins=20, alpha=0.7, label='Out-of-sample R-squared')\n",
    "plt.xlabel('R-squared')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of In-sample and Out-of-sample R-squared over Multiple Iterations')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d05049b",
   "metadata": {},
   "source": [
    "#### Explanation of Results\n",
    "\n",
    "By running this code, you will see histograms showing the distribution of in-sample and out-of-sample R-squared values across different train-test splits. Here’s the purpose and meaning behind this demonstration:\n",
    "\n",
    "1. Stability and Robustness: The spread of in-sample and out-of-sample R-squared values shows how stable the model is under varying train-test splits. A narrow spread in out-of-sample R-squared values indicates robustness, while a wide spread suggests that the model may be sensitive to the specific data it’s trained on.\n",
    "\n",
    "2. In-sample vs. Out-of-sample Performance: Consistently higher in-sample R-squared values compared to out-of-sample R-squared values can indicate overfitting, where the model performs well on training data but poorly on unseen data.\n",
    "\n",
    "3. Model Generalizability: If the out-of-sample R-squared values cluster close to the in-sample values, it suggests that the model generalizes well to new data.\n",
    "\n",
    "#### Purpose of the Demonstration\n",
    "\n",
    "The demonstration assesses model reliability by examining how performance metrics fluctuate across different data splits. This method provides insight into the model’s sensitivity to changes in the training data, which is valuable for understanding the model's expected performance in real-world applications where new data is unlikely to match the training set exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7e80e",
   "metadata": {},
   "source": [
    "# 9. Work with a ChatBot to understand the meaning of the illustration below; and, explain this in your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5eb36",
   "metadata": {},
   "source": [
    "#### Code Structure and Process\n",
    "\n",
    "1. Original Model (model6 and model7) Evaluation:\n",
    "\n",
    "- Both model6 and model7 were originally trained on the entire dataset. The code captures their in-sample R-squared (using the training set) and out-of-sample R-squared (using the test set) for reference.\n",
    "- These scores provide a baseline for comparison to see how much the training set composition affects generalization.\n",
    "\n",
    "\n",
    "2. Training on Generation 1 Only (gen1_predict_future):\n",
    "\n",
    "- New models based on model6 and model7 are trained exclusively on Generation 1 Pokémon data.\n",
    "- In-sample R-squared: This measures the model’s fit on Generation 1 data.\n",
    "- Out-of-sample R-squared: The models are tested on Pokémon from Generations 2 through 6 to evaluate how well they generalize to new generations. This highlights whether patterns learned from Generation 1 hold for subsequent generations.\n",
    "\n",
    "\n",
    "3. Training on Generations 1 to 5 (gen1to5_predict_future):\n",
    "\n",
    "- Additional models are created by training on Generations 1 through 5, excluding Generation 6.\n",
    "- In-sample R-squared: Evaluates fit on Generations 1–5.\n",
    "- Out-of-sample R-squared: The models are tested specifically on Generation 6 to see if they generalize to the newest generation.\n",
    "\n",
    "\n",
    "#### Interpretation of Results\n",
    "\n",
    "- Generalization Across Generations:\n",
    "\n",
    "a. High in-sample R-squared but low out-of-sample R-squared indicates that the model may not generalize well to Pokémon from different generations. This often occurs if characteristics of Pokémon vary substantially from generation to generation.\n",
    "b. A smaller gap between in-sample and out-of-sample R-squared suggests that the model generalizes better, meaning that learned relationships are applicable across different generations.\n",
    "\n",
    "\n",
    "- Training on Multiple Generations:\n",
    "\n",
    "a. Models trained on a broader range of data (Generations 1–5) generally perform better on out-of-sample data from Generation 6, indicating that exposure to a variety of patterns enhances generalizability.\n",
    "b. Conversely, models trained solely on Generation 1 may struggle to predict later generations accurately, suggesting that characteristics of Pokémon change over time, or new data introduces patterns not present in Generation 1.\n",
    "\n",
    "\n",
    "#### Purpose of the Demonstration\n",
    "\n",
    "- This illustration explores predictive generalizability:\n",
    "\n",
    "1. Single vs. Multiple Generations: Comparing models trained on single vs. multiple generations shows the importance of a diverse training set for capturing a range of characteristics.\n",
    "2. Evaluating Evolution in Data: By testing models on new data from different generations, this approach reveals whether underlying relationships remain stable or evolve over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcee8d0",
   "metadata": {},
   "source": [
    "# ChatGPT Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2835e2",
   "metadata": {},
   "source": [
    "Understanding Model Types and Variables:\n",
    "\n",
    "We started by discussing the difference between simple and multiple linear regression models, focusing on how adding more predictors can improve model explanation but may also increase complexity.\n",
    "We explored the effects of continuous and indicator variables in regression and how interactions between predictors influence the model. Including an interaction term allows the model to capture combined effects, which can improve predictions when variables influence each other.\n",
    "Building and Evaluating Models Using the Pokémon Dataset:\n",
    "\n",
    "Using the Pokémon dataset, we built different models (model3 to model7) that progressively added predictors and interactions.\n",
    "We discussed design matrices and how complex models with numerous interactions could lead to multicollinearity, causing instability in predictions. High Condition Numbers in these models highlighted this issue, and centering and scaling the data helped mitigate multicollinearity to some extent.\n",
    "Assessing Model Stability with Iterative Train-Test Splits:\n",
    "\n",
    "We ran a loop to fit models on randomly split train-test sets, omitting a fixed seed to introduce variability. By measuring in-sample and out-of-sample R-squared values across iterations, we visualized the model’s robustness.\n",
    "The variability in performance metrics illustrated how sensitive the model was to different splits, highlighting potential overfitting if in-sample performance consistently exceeded out-of-sample performance.\n",
    "Cross-Generational Generalization:\n",
    "\n",
    "We evaluated models trained on specific Pokémon generations (e.g., Generation 1 or Generations 1–5) to see how well they predicted on other generations, such as Generation 6. This approach aimed to test the model’s ability to generalize to future data.\n",
    "Models trained on more generations (1–5) performed better on Generation 6, indicating that more representative data improves generalizability. Models trained on Generation 1 alone struggled with later generations, suggesting that Pokémon characteristics vary across generations.\n",
    "Key Insights and Purpose:\n",
    "\n",
    "The progression from simple to complex models highlighted the balance between capturing detailed relationships and maintaining stability and interpretability. The importance of evaluating in-sample and out-of-sample performance was emphasized, as it reveals whether a model generalizes well or overfits.\n",
    "The analysis demonstrated the need for diverse training data to predict future data accurately. This cross-generational testing illustrated that broader training data helps the model generalize better to new data.\n",
    "\n",
    "### Final Summary\n",
    "Overall, the conversation illustrated a methodical approach to building, refining, and interpreting linear regression models with practical insights into the effects of model complexity, multicollinearity, robustness, and the importance of representative training data for reliable predictions. The key takeaway was that achieving a balance between capturing complex relationships and ensuring generalizability is essential for building robust predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e56a4",
   "metadata": {},
   "source": [
    "# ChatGPT Convo Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5edd25",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/67367d16-3570-8006-8a5c-104fb7b0dc2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
